{"cells":[{"cell_type":"markdown","source":["# \"BinaryA\" clasificación"],"metadata":{"id":"l0br1J7jLcL8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PLyQPN-bcutt"},"outputs":[],"source":["import re\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import scipy.stats as st\n","import sklearn.ensemble as en\n","import sklearn.feature_selection as fs\n","import sklearn.linear_model as lm\n","import sklearn.metrics as mt\n","import sklearn.model_selection as ms\n","import sklearn.neighbors as ne\n","import sklearn.preprocessing as pp\n","import sklearn.svm as svm\n","import sklearn.tree as tr\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import time as tm\n","import xgboost as xgb\n","from sklearn.dummy import DummyClassifier\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSF_4OaVcxUh"},"outputs":[],"source":["RANDOM_STATE=4+8+15+16+23+42\n","CROSS_VALIDATION_FOLDS=10#3,5,10\n","CROSS_VALIDATION_REPEATS=100#10, 100, 1000\n","HYPERPARAMETER_SEARCH_ITERATIONS=50#20, 50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-ISwb83Xr72"},"outputs":[],"source":["# Cargar datos\n","subdatasets_file = \"/content/drive/MyDrive/Documentos/7. educación/uniovi/master/tfm/data/BI_subconjuntos.txt\"\n","with open(subdatasets_file, 'r') as f:\n","    content = f.read()\n","subsets = content.split('------------------------------------------------------------\\n')\n","X_raw = pd.read_csv(\"/content/drive/MyDrive/Documentos/7. educación/uniovi/master/tfm/data/BinaryA_features.csv\")\n","y_raw = pd.read_csv(\"/content/drive/MyDrive/Documentos/7. educación/uniovi/master/tfm/data/BinaryA_labels.csv\")\n","y = y_raw.iloc[:, 1:].values.ravel() # Las etiquetas están en la segunda columna"]},{"cell_type":"code","source":["# Preprocesamiento\n","original_feature_names = X_raw.columns.tolist()\n","pipe = Pipeline([\n","  (\"feature_elimination\", fs.VarianceThreshold()),\n","  (\"scaler\", pp.StandardScaler())\n","])\n","X_preprocessed = pipe.fit_transform(X_raw)\n","preprocessed_feature_names = pipe.get_feature_names_out(input_features=original_feature_names)\n","X = pd.DataFrame(X_preprocessed, columns=preprocessed_feature_names)"],"metadata":{"id":"NvkG0_1VZsBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5b532622"},"source":["subset_values = {}\n","subset_dataframes = {}\n","added_subsets_features = {}\n","\n","for i, subset in enumerate(subsets):\n","    # Dividir en líneas y filtrar las que tienen $ y &\n","    lines = subset.split('\\n')\n","    feature_lines_raw = [line.split(' : ')[0].strip().lstrip('- ') for line in lines if line.strip() and not line.startswith('***') and '$' not in line and '&' not in line]\n","    feature_lines = [line for line in feature_lines_raw if line] #Líneas vacías\n","\n","    # Buscar $ (nombre)\n","    match_dollar = re.search(r'\\$(.*?)\\$', subset)\n","    if match_dollar:\n","        subset_values[f\"subset_{i+1}_value\"] = match_dollar.group(1)\n","    else:\n","        subset_values[f\"subset_{i+1}_value\"] = None\n","\n","    # Buscar & (tiempo)\n","    match_ampersand = re.search(r'&(.*?)&', subset)\n","    if match_ampersand:\n","        subset_values[f\"subset_{i+1}_time\"] = match_ampersand.group(1)\n","    else:\n","        subset_values[f\"subset_{i+1}_time\"] = None\n","\n","    # Limpiar nombres\n","    if feature_lines and feature_lines[-1].endswith('...'):\n","        truncated_name = feature_lines[-1].replace('...', '').strip()\n","        matching_columns = [col for col in X.columns if col.startswith(truncated_name)]\n","        if matching_columns:\n","             feature_lines[-1] = matching_columns[0] # Usar la primera coincidencia\n","        else:\n","            print(f\"No se encontró el nombre de la característica para la entrada truncada: {truncated_name}\")\n","\n","    # Comprobar que las características existen\n","    valid_feature_names = [name for name in feature_lines if name in X_raw.columns]\n","    if len(valid_feature_names) != len(feature_lines):\n","        missing = set(feature_lines) - set(valid_feature_names)\n","        missing_filtered = {item for item in missing if '$' not in item and '&' not in item}\n","        if missing_filtered:\n","            print(f\"Las características del subconjunto {i+1} no se encontraron: {missing_filtered}\")\n","\n","    # Ordenar alfabéticamente\n","    valid_feature_names.sort()\n","    current_subset_features = tuple(valid_feature_names)\n","\n","    # Comprobar si este subconjunto de características ya existe\n","    if current_subset_features not in added_subsets_features:\n","        subset_dataframes[f\"subset_{i+1}\"] = X_raw[valid_feature_names]\n","        added_subsets_features[current_subset_features] = f\"subset_{i+1}\"\n","        print(f\"DataFrame creado para el subconjunto {i+1} ({subset_values.get(f'subset_{i+1}_value', 'N/A')}) con {len(valid_feature_names)} características.\")\n","    else:\n","        original_subset_key = added_subsets_features[current_subset_features]\n","        original_subset_name = subset_values.get(f'{original_subset_key}_value', original_subset_key)\n","        current_subset_name = subset_values.get(f'subset_{i+1}_value', f'subset_{i+1}')\n","        combined_name = f\"{original_subset_name} + {current_subset_name}\" # Crear un nombre combinado\n","\n","        # Renombrar el subconjunto original\n","        subset_dataframes[combined_name] = subset_dataframes.pop(original_subset_key)\n","        subset_values[f'{combined_name}_value'] = combined_name\n","\n","        # Añadir el subconjunto actual con el mismo nombre combinado\n","        subset_dataframes[combined_name] = X_raw[valid_feature_names]\n","        added_subsets_features[current_subset_features] = combined_name\n","\n","        print(f\"Subconjunto {i+1} (Nombre: {current_subset_name}, Tiempo: {subset_values.get(f'subset_{i+1}_time', 'N/A')}) tiene las mismas características que el subconjunto original (Nombre: {original_subset_name}). Renombrado a: {combined_name}.\")\n","        # Eliminar las entradas antiguas de valor y tiempo para el subconjunto actual\n","        subset_values.pop(f'subset_{i+1}_value', None)\n","        subset_values.pop(f'subset_{i+1}_time', None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Estrategias de validación cruzada\n","cv_strategies = [\n","    ms.RepeatedKFold(n_splits = CROSS_VALIDATION_FOLDS,\n","                     n_repeats = CROSS_VALIDATION_REPEATS,\n","                     random_state=RANDOM_STATE),\n","    ms.ShuffleSplit(n_splits = CROSS_VALIDATION_FOLDS,\n","                    random_state=RANDOM_STATE),\n","    ms.RepeatedStratifiedKFold(n_splits = CROSS_VALIDATION_FOLDS,\n","                               n_repeats = CROSS_VALIDATION_REPEATS,\n","                               random_state=RANDOM_STATE),\n","    ms.StratifiedShuffleSplit(n_splits = CROSS_VALIDATION_FOLDS,\n","                              random_state=RANDOM_STATE)\n","]\n"],"metadata":{"id":"8V8oxbw46UzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Métricas\n","scorings = {\n","  \"Exactitud\": \"accuracy\",\n","  \"Exactitud balanceada\": \"balanced_accuracy\",\n","  \"Precisión\": mt.make_scorer(mt.precision_score, zero_division=np.nan),\n","  \"Precisión balanceada\": mt.make_scorer(mt.precision_score, average=\"weighted\", zero_division=np.nan),\n","  \"Sensibilidad\": \"recall\",\n","  \"Sensibilidad balanceada\": mt.make_scorer(mt.recall_score, average=\"weighted\"),\n","  \"ROC-AUC\": \"roc_auc\",\n","  \"ROC-AUC balanceada\": mt.make_scorer(mt.roc_auc_score, average=\"weighted\")\n","  }"],"metadata":{"id":"sLPjbAT-GDhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Clasificadores\n","classifiers = [\n","    (\"AdaBoost\", en.AdaBoostClassifier()),\n","    (\"ArbolesExtra\", tr.ExtraTreeClassifier()),\n","    (\"BosquesAleatorios\", en.RandomForestClassifier()),\n","    (\"Dummy\", DummyClassifier(strategy=\"most_frequent\")),\n","    (\"KNeighbors\", ne.KNeighborsClassifier()),\n","    (\"SVCLineal\", svm.SVC(probability=True)),\n","    (\"SVCNoLineal\", svm.SVC(kernel=\"rbf\", probability=True)),\n","    (\"XGBoost\", xgb.XGBClassifier())\n","]"],"metadata":{"id":"fUyhozYDAgoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Búsqueda de hiperparámetros\n","classifier_param_distributions = {\n","    \"AdaBoost\": {\n","        'AdaBoost__n_estimators': st.randint(50, 500),\n","        'AdaBoost__learning_rate': st.uniform(0.01, 1.0)\n","    },\n","    \"ArbolesExtra\": {\n","        'ArbolesExtra__max_depth': st.randint(3, 11)\n","    },\n","    \"BosquesAleatorios\": {\n","        'BosquesAleatorios__n_estimators': st.randint(100, 1000),\n","        'BosquesAleatorios__max_depth': st.randint(3, 11)\n","    },\n","    \"Dummy\": {},\n","    \"KNeighbors\": {\n","        'KNeighbors__n_neighbors': st.randint(1, 30)\n","    },\n","    \"SVCLineal\": {\n","        'SVCLineal__C': st.uniform(0.01, 10),\n","        'SVCLineal__gamma': st.uniform(0.01, 10)\n","    },\n","    \"SVCNoLineal\": {\n","        'SVCNoLineal__C': st.uniform(0.01, 10),\n","        'SVCNoLineal__gamma': st.uniform(0.01, 10)\n","    },\n","    \"XGBoost\": {\n","        'XGBoost__n_estimators': st.randint(100, 1000),\n","        'XGBoost__learning_rate': st.uniform(0.01, 0.29),\n","        'XGBoost__max_depth': st.randint(3, 11)\n","    }\n","}"],"metadata":{"id":"Kvz2o4y9bMLt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ict7QaHMe41z"},"outputs":[],"source":["all_metrics = []\n","\n","for i, (subset_name, X_subset) in enumerate(subset_dataframes.items()):\n","    display_subset_name = subset_values.get(f'{subset_name}_value', 'N/A')\n","    print(f\"--- Subconjunto {i+1}: {display_subset_name} ---\")\n","\n","    for clf_name, classifier in classifiers:\n","        print(f\"--- Clasificador: {clf_name} ---\")\n","\n","        full_pipeline = Pipeline([\n","            (\"feature_elimination\", fs.VarianceThreshold()),\n","            (\"scaler\", pp.StandardScaler()),\n","            (clf_name, classifier)\n","        ])\n","\n","        # Si hay hiperparámetros, realizar la búsqueda\n","        if clf_name in classifier_param_distributions:\n","            param_distributions = classifier_param_distributions[clf_name]\n","\n","            for cv_strategy in cv_strategies:\n","\n","                hyperparameter_search = ms.GridSearchCV(\n","                    estimator=full_pipeline,\n","                    param_distributions=param_distributions,\n","                    cv=cv_strategy,\n","                    n_iter=HYPERPARAMETER_SEARCH_ITERATIONS,\n","                    random_state=RANDOM_STATE,\n","                    scoring=scorings,\n","                    refit='ROC-AUC'\n","                )\n","\n","                clf_best = hyperparameter_search.fit(X_subset, y)\n","\n","                print(\"*** Iteraciones:\", HYPERPARAMETER_SEARCH_ITERATIONS, \"***\")\n","                print(\"*** CV:\", type(cv_strategy).__name__,\n","                      \", folds:\", CROSS_VALIDATION_FOLDS,\n","                      \", repeticiones:\", CROSS_VALIDATION_REPEATS, \"***\")\n","\n","                print(\"Mejor combinación:\")\n","                best_parameters = hyperparameter_search.best_estimator_.get_params()\n","\n","                # Mostrar solo los hiperparámetros optimizados\n","                optimized_params = {param_name: best_parameters[param_name] for param_name in param_distributions.keys()}\n","                for param_name, param_value in optimized_params.items():\n","                  print(f\"{param_name}: {param_value}\")\n","                print(\"-\" * 60)\n","\n","                print(\"Métricas del mejor modelo (validación cruzada):\")\n","                results = hyperparameter_search.cv_results_\n","                best_index = hyperparameter_search.best_index_\n","\n","                metrics = {\n","                    'Subconjunto': display_subset_name,\n","                    'Clasificador': clf_name,\n","                    'Estrategia CV': type(cv_strategy).__name__,\n","                    'Iteraciones HS': HYPERPARAMETER_SEARCH_ITERATIONS,\n","                    'CV folds': CROSS_VALIDATION_FOLDS,\n","                    'CV repeats': CROSS_VALIDATION_REPEATS if isinstance(cv_strategy, ms.RepeatedStratifiedKFold) else 1,\n","                    'Exactitud': results['mean_test_Exactitud'][best_index],\n","                    'Exactitud balanceada': results['mean_test_Exactitud balanceada'][best_index],\n","                    'Precisión': results['mean_test_Precisión'][best_index],\n","                    'Precisión balanceada': results['mean_test_Precisión balanceada'][best_index],\n","                    'Sensibilidad': results['mean_test_Sensibilidad'][best_index],\n","                    'Sensibilidad balanceada': results['mean_test_Sensibilidad balanceada'][best_index],\n","                    'Especificidad': 2 * results['mean_test_Exactitud balanceada'][best_index] - results['mean_test_Sensibilidad'][best_index],\n","                    'ROC-AUC': results['mean_test_ROC-AUC'][best_index],\n","                    'ROC-AUC balanceada': results['mean_test_ROC-AUC balanceada'][best_index],\n","                    'Tiempo': results['mean_fit_time'][best_index],\n","                    'Mejores hiperparámetros': optimized_params\n","                }\n","                all_metrics.append(metrics)\n","\n","                print(f\"Exactitud              : {metrics['Exactitud']}\")\n","                print(f\"Exactitud balanceada   : {metrics['Exactitud balanceada']}\")\n","                print(f\"Precisión              : {metrics['Precisión']}\")\n","                print(f\"Precisión balanceada   : {metrics['Precisión balanceada']}\")\n","                print(f\"Sensibilidad           : {metrics['Sensibilidad']}\")\n","                print(f\"Sensibilidad balanceada: {metrics['Sensibilidad balanceada']}\")\n","                print(f\"Especificidad          : {metrics['Especificidad']}\")\n","                print(f\"ROC-AUC                : {metrics['ROC-AUC']}\")\n","                print(f\"ROC-AUC balanceada     : {metrics['ROC-AUC balanceada']}\")\n","                print(f\"Tiempo                 : {metrics['Tiempo']}\")\n","                print(\"-\" * 30)\n","\n","        else: # Si no hay distribuciones, usar hiperparámetros por defecto\n","            print(\"Hiperparámetros por defecto...\")\n","            for cv_strategy in cv_strategies:\n","                clf_default = full_pipeline\n","\n","                scores = ms.cross_validate(\n","                    estimator=clf_default,\n","                    X=X_subset,\n","                    y=y,\n","                    cv=cv_strategy,\n","                    scoring=scorings,\n","                    return_train_score=False\n","                )\n","\n","                print(\"*** CV:\", type(cv_strategy).__name__,\n","                      \", folds:\", CROSS_VALIDATION_FOLDS,\n","                      \", repeticiones:\", CROSS_VALIDATION_REPEATS, \"***\")\n","\n","                metrics = {\n","                    'Subconjunto': display_subset_name,\n","                    'Clasificador': clf_name,\n","                    'Estrategia CV': type(cv_strategy).__name__,\n","                    'Iteraciones HS': 'N/A',\n","                    'CV folds': CROSS_VALIDATION_FOLDS,\n","                    'CV repeats': CROSS_VALIDATION_REPEATS if isinstance(cv_strategy, ms.RepeatedStratifiedKFold) else 1,\n","                    'Exactitud': scores['test_Exactitud'].mean(),\n","                    'Exactitud blanceada': scores['test_Exactitud balanceada'].mean(),\n","                    'Precisión': scores['test_Precisión'].mean() if not np.isnan(scores['test_Precisión'].mean()) else 'N/A',\n","                    'Precisión balanceada': scores['test_Precisión balanceada'].mean() if not np.isnan(scores['test_Precisión balanceada'].mean()) else 'N/A',\n","                    'Sensibilidad': scores['test_Sensibilidad'].mean(),\n","                    'Sensibilidad balanceada': scores['test_Sensibilidad balanceada'].mean(),\n","                    'Especificidad': 2 * scores['test_Exactitud balanceada'].mean() - scores['test_Sensibilidad'].mean(),\n","                    'ROC-AUC': scores['test_ROC-AUC'].mean() if not np.isnan(scores['test_ROC-AUC'].mean()) else 'N/A',\n","                    'ROC-AUC balanceada': scores['test_ROC-AUC balanceada'].mean() if not np.isnan(scores['test_ROC-AUC balanceada'].mean()) else 'N/A',\n","                    'Tiempo': scores['fit_time'].mean(),\n","                    'Mejores hiperparámetros': 'N/A'\n","                }\n","                all_metrics.append(metrics)\n","\n","                print(f\"Exactitud              : {metrics['Exactitud']}\")\n","                print(f\"Exactitud balanceada   : {metrics['Exactitud balanceada']}\")\n","                print(f\"Precisión              : {metrics['Precisión']}\")\n","                print(f\"Precisión balanceada   : {metrics['Precisión balanceada']}\")\n","                print(f\"Sensibilidad           : {metrics['Sensibilidad']}\")\n","                print(f\"Sensibilidad balanceada: {metrics['Sensibilidad balanceada']}\")\n","                print(f\"Especificidad          : {metrics['Especificidad']}\")\n","                print(f\"ROC-AUC                : {metrics['ROC-AUC']}\")\n","                print(f\"ROC-AUC balanceada     : {metrics['ROC-AUC balanceada']}\")\n","                print(f\"Tiempo                 : {metrics['Tiempo']}\")\n","                print(\"-\" * 30)\n","\n","        print(\"=\" * 80)\n","    print(\"=\" * 80)\n","\n","metrics_df = pd.DataFrame(all_metrics)"]},{"cell_type":"code","metadata":{"id":"d6b22b58"},"source":["# Ordenar subconjunto únicos alfabéticamente\n","sorted_subset_names = sorted(metrics_df['Subconjunto'].unique())\n","\n","for i, subset_name in enumerate(sorted_subset_names):\n","    for cv_strategy_name in metrics_df['Estrategia CV'].unique():\n","        filtered_df = metrics_df[(metrics_df['Subconjunto'] == subset_name) & (metrics_df['Estrategia CV'] == cv_strategy_name)].copy()\n","\n","        if not filtered_df.empty:\n","            columns_to_exclude = ['Subconjunto', 'Clasificador', 'Estrategia CV', 'Iteraciones HS',\n","                                 'CV folds', 'CV repeats', 'Tiempo', 'Mejores hiperparámetros']\n","\n","            # Usar las columnas que no están en la lista de exclusión como métricas\n","            metric_columns = [col for col in filtered_df.columns if col not in columns_to_exclude]\n","            melted_df = filtered_df.melt(id_vars='Clasificador',\n","                                         value_vars=metric_columns,\n","                                         var_name='Métrica',\n","                                         value_name='Puntuación')\n","            heatmap_data = melted_df.pivot_table(index='Clasificador', columns='Métrica', values='Puntuación')\n","\n","            # Comprobar si está vacío\n","            if heatmap_data.empty or heatmap_data.isnull().all().all():\n","                display_subset_name = subset_values.get(f'{subset_name}_value', subset_name)\n","                print(f\"Saltando para el subconjunto '{display_subset_name}' y estrategia CV '{cv_strategy_name}' debido a que los datos están vacíos o contienen solo valores NaN.\")\n","                continue\n","\n","            # Usar .get() con el nombre del subconjunto como valor por defecto\n","            display_subset_name = subset_values.get(f'{subset_name}_value', subset_name)\n","            subset_time_key = f'{subset_name}_time'\n","            subset_time = subset_values.get(subset_time_key, 'N/A')\n","\n","            plt.figure(figsize=(10, 6))\n","            sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"viridis\")\n","            plt.title(f'{display_subset_name}')\n","            plt.xlabel('Métrica')\n","            plt.ylabel('Clasificador')\n","            plt.tight_layout()\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1e2c6bc"},"source":["columns_to_exclude = ['Subconjunto', 'Clasificador', 'Estrategia CV', 'Iteraciones HS',\n","                     'CV folds', 'CV repeats', 'Tiempo', 'Mejores hiperparámetros']\n","metric_columns = [col for col in metrics_df.columns if col not in columns_to_exclude]\n","\n","for metric_name in metric_columns:\n","    for cv_strategy_name in metrics_df['Estrategia CV'].unique():\n","        filtered_df = metrics_df[(metrics_df['Estrategia CV'] == cv_strategy_name)].copy()\n","\n","        if not filtered_df.empty:\n","            # Usar nombre como índice, Classifier como columnas y la métrica actual como valores\n","            heatmap_data = filtered_df.pivot_table(index='Subconjunto', columns='Clasificador', values=metric_name)\n","\n","            subset_name_mapping = {name: subset_values.get(f'{name}_value', name) for name in heatmap_data.index}\n","            heatmap_data = heatmap_data.rename(index=subset_name_mapping)\n","\n","            # Ordenar alfabéticamente las filas\n","            heatmap_data = heatmap_data.sort_index()\n","\n","            plt.figure(figsize=(12, 8))\n","            sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"viridis\")\n","            plt.title(f'{metric_name}')\n","            plt.xlabel('Clasificador')\n","            plt.ylabel('Subconjunto')\n","            plt.tight_layout()\n","            plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78dbb14c"},"source":["# Obtener la lista de métricas\n","columns_to_exclude = ['Estrategia CV', 'Iteraciones HS',\n","                     'CV folds', 'CV repeats', 'Tiempo', 'Mejores hiperparámetros', 'Subconjunto', 'Clasificador']\n","metric_columns = [col for col in metrics_df.columns if col not in columns_to_exclude]\n","\n","# Excluir el clasificador \"Dummy\"\n","filtered_metrics_df = metrics_df[metrics_df['Clasificador'] != 'Dummy'].copy()\n","\n","\n","# Agrupar por subconjunto para encontrar el mejor valor\n","best_scores_indices = filtered_metrics_df.groupby('Subconjunto')[metric_columns].idxmax()\n","\n","best_scores = filtered_metrics_df.loc[best_scores_indices.stack()]\n","best_scores = best_scores.reset_index()\n","best_scores_melted = best_scores.melt(id_vars=['Subconjunto', 'Clasificador'],\n","                                      value_vars=metric_columns,\n","                                      var_name='Métrica',\n","                                      value_name='Mejor Puntuación')\n","\n","best_scores_melted['Annotation'] = best_scores_melted.apply(lambda row: f\"{row['Mejor Puntuación']:.2f}\\n({row['Clasificador']})\", axis=1)\n","heatmap_pivot_annotation = best_scores_melted.pivot_table(index='Subconjunto', columns='Métrica', values='Annotation', aggfunc='first') # Use 'first' to avoid joining multiple annotations\n","heatmap_pivot_values = best_scores_melted.pivot_table(index='Subconjunto', columns='Métrica', values='Mejor Puntuación')\n","\n","# Mapear los nombres de los subconjuntos en el índice\n","subset_name_mapping = {name: subset_values.get(f'{name}_value', name) for name in heatmap_pivot_annotation.index}\n","heatmap_pivot_annotation = heatmap_pivot_annotation.rename(index=subset_name_mapping)\n","heatmap_pivot_values = heatmap_pivot_values.rename(index=subset_name_mapping)\n","\n","# Ordenar alfabéticamente las filas\n","heatmap_pivot_annotation = heatmap_pivot_annotation.sort_index()\n","heatmap_pivot_values = heatmap_pivot_values.sort_index()\n","\n","plt.figure(figsize=(22, 12))\n","sns.heatmap(heatmap_pivot_values, annot=heatmap_pivot_annotation, fmt=\"\", cmap=\"viridis\", annot_kws={\"size\": 12}) # Increase font size here\n","plt.title('Mejor valor y clasificador')\n","plt.xlabel('Métrica')\n","plt.ylabel('Subconjunto')\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"48d0ac27"},"source":["# Suma de los tiempos por clasificador\n","total_time_per_classifier = metrics_df.groupby('Clasificador')['Tiempo'].sum()\n","\n","print(\"Suma total de tiempos:\")\n","print(total_time_per_classifier)"],"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}